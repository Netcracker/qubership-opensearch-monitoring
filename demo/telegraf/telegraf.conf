# Telegraf Configuration
#
# Telegraf is entirely plugin driven. All metrics are gathered from the
# declared inputs, and sent to the declared outputs.
#
# Plugins must be declared in here to be active.
# To deactivate a plugin, comment out the name and any variables.
#
# Use 'telegraf -config telegraf.conf -test' to see what metrics a config
# file would generate.
#
# Environment variables can be used anywhere in this config file, simply prepend
# them with $. For strings the variable must be within quotes (ie, "$STR_VAR"),
# for numbers and booleans they should be plain (ie, $INT_VAR, $BOOL_VAR)


# Global tags can be specified here in key="value" format.
[global_tags]
  # dc = "us-east-1" # will tag all metrics with dc=us-east-1
  # rack = "1a"
  ## Environment variables can be used as tags, and throughout the config file
  # user = "$USER"
  project_name= "$OS_PROJECT"


# Configuration for telegraf agent
[agent]
  ## Default data collection interval for all inputs
  interval = "$ELASTICSEARCH_EXEC_PLUGIN_TIMEOUT"
  ## Rounds collection interval to 'interval'
  ## ie, if interval="10s" then always collect on :00, :10, :20, etc.
  round_interval = true

  ## Telegraf will send metrics to outputs in batches of at most
  ## metric_batch_size metrics.
  ## This controls the size of writes that Telegraf sends to output plugins.
  metric_batch_size = 1000

  ## For failed writes, telegraf will cache metric_buffer_limit metrics for each
  ## output, and will flush this buffer on a successful write. Oldest metrics
  ## are dropped first when this buffer fills.
  ## This buffer only fills when writes fail to output plugin(s).
  metric_buffer_limit = 10000

  ## Collection jitter is used to jitter the collection by a random amount.
  ## Each plugin will sleep for a random time within jitter before collecting.
  ## This can be used to avoid many plugins querying things like sysfs at the
  ## same time, which can have a measurable effect on the system.
  collection_jitter = "0s"

  ## Default flushing interval for all outputs. You shouldn't set this below
  ## interval. Maximum flush_interval will be flush_interval + flush_jitter
  flush_interval = "10s"
  ## Jitter the flush interval by a random amount. This is primarily to avoid
  ## large write spikes for users running a large number of telegraf instances.
  ## ie, a jitter of 5s and interval 10s means flushes will happen every 10-15s
  flush_jitter = "0s"

  ## By default, precision will be set to the same timestamp order as the
  ## collection interval, with the maximum being 1s.
  ## Precision will NOT be used for service inputs, such as logparser and statsd.
  ## Valid values are "ns", "us" (or "Âµs"), "ms", "s".
  precision = ""

  ## Logging configuration:
  ## Run telegraf with debug log messages.
  debug = $DEBUG
  ## Run telegraf in quiet mode (error log messages only).
  quiet = false
  ## Specify the log file name. The empty string means to log to stderr.
  logfile = ""

  ## Override default hostname, if empty use os.Hostname()
  hostname = ""
  ## If set to true, do no set the "host" tag in the telegraf agent.
  omit_hostname = false


###############################################################################
#                            OUTPUT PLUGINS                                   #
###############################################################################

# Configuration for influxdb server to send metrics to
[[outputs.influxdb]]
  ## The full HTTP or UDP endpoint URL for your InfluxDB instance.
  ## Multiple urls can be specified as part of the same cluster,
  ## this means that only ONE of the urls will be written to each interval.
  # urls = ["udp://localhost:8089"] # UDP endpoint example
  urls = ["$SM_DB_HOST"] # required
  ## The target database for metrics (telegraf will create it if not exists).
  database = "$SM_DB_NAME" # required

  ## Retention policy to write to. Empty string writes to the default rp.
  retention_policy = ""
  ## Write consistency (clusters only), can be: "any", "one", "quorum", "all"
  write_consistency = "any"

  ## Write timeout (for the InfluxDB client), formatted as a string.
  ## If not provided, will default to 5s. 0s means no timeout (not recommended).
  timeout = "5s"
  username = "$SM_DB_USERNAME"
  password = "$SM_DB_PASSWORD"
  ## Set the user agent for HTTP POSTs (can be useful for log differentiation)
  # user_agent = "telegraf"
  ## Set UDP payload size, defaults to InfluxDB UDP Client default (512 bytes)
  # udp_payload = 512

  ## Optional SSL Config
  # ssl_ca = "/etc/telegraf/ca.pem"
  # ssl_cert = "/etc/telegraf/cert.pem"
  # ssl_key = "/etc/telegraf/key.pem"
  ## Use SSL but skip chain & host verification
  # insecure_skip_verify = false

# # Publish all metrics to /metrics for Prometheus to scrape
# [[outputs.prometheus_client]]
#   ## Address to listen on.
#   listen = ":8096"
#
#   ## Metric version controls the mapping from Telegraf metrics into
#   ## Prometheus format.  When using the prometheus input, use the same value in
#   ## both plugins to ensure metrics are round-tripped without modification.
#   ##
#   ##   example: metric_version = 1; deprecated in 1.13
#   ##            metric_version = 2; recommended version
#   # metric_version = 1
#
#   ## Use HTTP Basic Authentication.
#   basic_username = "$PROMETHEUS_USERNAME"
#   basic_password = "$PROMETHEUS_PASSWORD"
#   ## If set, the IP Ranges which are allowed to access metrics.
#   ##   ex: ip_range = ["192.168.0.0/24", "192.168.1.0/30"]
#   # ip_range = []
#
#   ## Path to publish the metrics on.
#   # path = "/metrics"
#
#   ## Expiration interval for each metric. 0 == no expiration
#   # expiration_interval = "60s"
#   expiration_interval = "${PROCESSING_INTERVAL_MINUTES}m"
#
#   ## Collectors to enable, valid entries are "gocollector" and "process".
#   ## If unset, both are enabled.
#   # collectors_exclude = ["gocollector", "process"]
#
#   ## Send string metrics as Prometheus labels.
#   ## Unless set to false all string metrics will be sent as labels.
#   # string_as_label = true
#
#   ## If set, enable TLS with the given certificate.
#   # tls_cert = "/etc/ssl/telegraf.crt"
#   # tls_key = "/etc/ssl/telegraf.key"
#
#   ## Set one or more allowed client CA certificate file names to
#   ## enable mutually authenticated TLS connections
#   # tls_allowed_cacerts = ["/etc/telegraf/clientca.pem"]
#
#   ## Export metric collection time.
#   # export_timestamp = false


###############################################################################
#                            PROCESSOR PLUGINS                                #
###############################################################################


###############################################################################
#                            AGGREGATOR PLUGINS                               #
###############################################################################

# # Keep the aggregate min/max of each metric passing through.
# [[aggregators.minmax]]
#   ## General Aggregator Arguments:
#   ## The period on which to flush & clear the aggregator.
#   period = "30s"
#   ## If true, the original metric will be dropped by the
#   ## aggregator and will not get sent to the output plugins.
#   drop_original = false


###############################################################################
#                            INPUT PLUGINS                                    #
###############################################################################

# Read metrics about cpu usage
[[inputs.cpu]]
  ## Whether to report per-cpu stats or not
  percpu = true
  ## Whether to report total system cpu stats or not
  totalcpu = true
  ## If true, collect raw CPU time metrics.
  collect_cpu_time = false
  ##Specifies a prefix to attach to the measurement name.


# Read metrics about disk usage by mount point
[[inputs.disk]]
  ## By default, telegraf gather stats for all mountpoints.
  ## Setting mountpoints will restrict the stats to the specified mountpoints.
  # mount_points = ["/"]

  ## Ignore some mountpoints by filesystem type. For example (dev)tmpfs (usually
  ## present on /run, /var/run, /dev/shm or /dev).
  ignore_fs = ["tmpfs", "devtmpfs"]
  ##Specifies a prefix to attach to the measurement name.


# Read metrics about disk IO by device
[[inputs.diskio]]
  ## By default, telegraf will gather stats for all devices including
  ## disk partitions.
  ## Setting devices will restrict the stats to the specified devices.
  # devices = ["sda", "sdb"]
  ## Uncomment the following line if you need disk serial numbers.
  # skip_serial_number = false
  ##Specifies a prefix to attach to the measurement name.


# Get kernel statistics from /proc/stat
[[inputs.kernel]]
  # no configuration
  ##Specifies a prefix to attach to the measurement name.

# Read metrics about memory usage
[[inputs.mem]]
  # no configuration
  ##Specifies a prefix to attach to the measurement name.

# Get the number of processes and group them by status
[[inputs.processes]]
  # no configuration
  ##Specifies a prefix to attach to the measurement name.

# Read metrics about swap memory usage
[[inputs.swap]]
  # no configuration
  ##Specifies a prefix to attach to the measurement name.

# Read metrics about system load & uptime
[[inputs.system]]
  # no configuration
  ##Specifies a prefix to attach to the measurement name.

# Read stats from one or more Elasticsearch servers or clusters
[[inputs.elasticsearch]]
   # An array of glob pattern strings.
   # Fields with a field key matching one of the patterns will be discarded from the metric.
   fielddrop = ["status_code"]

   ## specify a list of one or more Elasticsearch servers
   # you can add username and password to your url to use basic authentication:
   # servers = ["http://user:pass@localhost:9200"]
   servers = ["$ELASTICSEARCH_PROTOCOL://$ELASTICSEARCH_CREDENTIALS@$ELASTICSEARCH_HOST:$ELASTICSEARCH_PORT"]

   ## Timeout for HTTP requests to the elastic search server(s)
   http_timeout = "8s"

   ## When local is true (the default), the node will read only its own stats.
   ## Set local to false when you want to read the node stats from all nodes
   ## of the cluster.
   local = false

   ## Set cluster_health to true when you want to also obtain cluster health stats
   cluster_health = true

   ## Set cluster_stats to true when you want to also obtain cluster stats from the
   ## Master node.
   cluster_stats = true

   ## node_stats is a list of sub-stats that you want to have gathered. Valid options
   ## are "indices", "os", "process", "jvm", "thread_pool", "fs", "transport", "http",
   ## "breaker". Per default, all stats are gathered.
   # node_stats = ["jvm", "http"]

   ## Optional TLS Config
   tls_ca = "$ROOT_CA_CERTIFICATE"
   # tls_cert = "/etc/telegraf/cert.pem"
   # tls_key = "/etc/telegraf/key.pem"
   ## Use TLS but skip chain & host verification
   insecure_skip_verify = $INSECURE_SKIP_VERIFY

  ##Specifies a prefix to attach to the measurement name.


# Read metrics from one or more commands that can output to stdout
[[inputs.exec]]
  ## Commands array
  commands = [
  # "python3 /opt/elasticsearch-monitoring/exec-scripts/replication_metric.py",
    "python3 /opt/elasticsearch-monitoring/exec-scripts/health_metric.py",
    "python3 /opt/elasticsearch-monitoring/exec-scripts/backup_metric.py",
    "python3 /opt/elasticsearch-monitoring/exec-scripts/dbaas_health_metric.py"
  ]

  ## Timeout for each command to complete.
  timeout = "$ELASTICSEARCH_EXEC_PLUGIN_TIMEOUT"

  ## measurement name suffix (for separating different commands)
  # name_prefix = "elasticsearch_"

  ## Data format to consume.
  ## Each data format has it's own unique set of configuration options, read
  ## more about them here:
  ## https://github.com/influxdata/telegraf/blob/master/docs/DATA_FORMATS_INPUT.md
  data_format = "influx"

# # Read metrics from one or more commands that can output to stdout
# [[inputs.exec]]
#   ## Commands array
#   commands = [
#     "python3 /opt/elasticsearch-monitoring/exec-scripts/slow_queries_metric.py"
#   ]
#
#   interval = "${PROCESSING_INTERVAL_MINUTES}m"
#
#   ## Timeout for each command to complete.
#   timeout = "$ELASTICSEARCH_EXEC_PLUGIN_TIMEOUT"
#
#   ## measurement name suffix (for separating different commands)
#   # name_prefix = "elasticsearch_"
#
#   ## Data format to consume.
#   ## Each data format has it's own unique set of configuration options, read
#   ## more about them here:
#   ## https://github.com/influxdata/telegraf/blob/master/docs/DATA_FORMATS_INPUT.md
#   data_format = "influx"
